{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsF4jFqvHyoX"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbNXbAiVHyoc"
      },
      "source": [
        "# Introduction to Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64QLF5JGHyoc"
      },
      "source": [
        "## What's TensorFlow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTtwhMdvHyod"
      },
      "source": [
        "## What's Keras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGBfWs6CHyod"
      },
      "source": [
        "## Keras and TensorFlow: A brief history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf_4WMLgHyoe"
      },
      "source": [
        "## Setting up a deep-learning workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX-ecfCNHyoe"
      },
      "source": [
        "### Jupyter notebooks: The preferred way to run deep-learning experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2En2658OHyof"
      },
      "source": [
        "### Using Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbJXkEpbHyof"
      },
      "source": [
        "#### First steps with Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vl_PLPjHyog"
      },
      "source": [
        "#### Installing packages with pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3i42SJTHyoh"
      },
      "source": [
        "#### Using the GPU runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJKDA3f2Hyoh"
      },
      "source": [
        "## First steps with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdM22GJ5Hyoh"
      },
      "source": [
        "#### Constant tensors and variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2tTZSePHyoi"
      },
      "source": [
        "**All-ones or all-zeros tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KIqdwodfII9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eWyXv4TtHyoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2422bb04-7dab-4320-ebfa-cd6385d48a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.]\n",
            " [1.]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "x = tf.ones(shape=(2, 1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l2URsVPjHyoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee06ae8-948a-467d-a2c2-f9fca89b1459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.zeros(shape=(2, 1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afGQ6cmwHyoj"
      },
      "source": [
        "**Random tensors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rNvK2WEuHyok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240faf80-ceca-4e10-b5c5-4faae7bcad68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.84900045]\n",
            " [-1.2728714 ]\n",
            " [-0.7707765 ]], shape=(3, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.random.normal(shape=(3, 1), mean=0., stddev=1.)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6ytwnpNpHyok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2cd222-6815-4898-a742-64f58f04c2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.558252  ]\n",
            " [0.04556024]\n",
            " [0.2309941 ]], shape=(3, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A significant difference between NumPy arrays and TensorFlow tensors is that Tensor Flow tensors aren’t assignable: they’re constant. For instance, in NumPy, you can do the following"
      ],
      "metadata": {
        "id": "aj-CqQU8ItWQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4201kDAHyok"
      },
      "source": [
        "**NumPy arrays are assignable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elIhyNLZHyol"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.ones(shape=(2, 2))\n",
        "x[0, 0] = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5F-bPnLHyol"
      },
      "source": [
        "**Creating a TensorFlow variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yCzBJdtBHyol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8819eed-d8b8-4222-dd44-0dc7d9112d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[0.81706274],\n",
            "       [0.9615755 ],\n",
            "       [0.2497994 ]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3, 1)))\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qocFef2LHyol"
      },
      "source": [
        "**Assigning a value to a TensorFlow variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nf4M0Dv-Hyom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74debaa0-2a25-4517-98f4-0ea1823f436f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "v.assign(tf.ones((3, 1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGK2MH-DHyom"
      },
      "source": [
        "**Assigning a value to a subset of a TensorFlow variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I9_XKBRYHyom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e19f1f-32b9-48d5-fcf8-df36bbf0ab52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
              "array([[3.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "v[0, 0].assign(3.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhYwFpk8Hyom"
      },
      "source": [
        "**Using `assign_add`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iPEmZBEPHyom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29147acf-a1dc-4483-ae7b-63e161fcd16b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
              "array([[4.],\n",
              "       [2.],\n",
              "       [2.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "v.assign_add(tf.ones((3, 1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbjK-fMqHyom"
      },
      "source": [
        "#### Tensor operations: Doing math in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z3E4dTQHyon"
      },
      "source": [
        "**A few basic math operations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BGDAJ6BSHyon"
      },
      "outputs": [],
      "source": [
        "a = tf.ones((2, 2))\n",
        "b = tf.square(a)\n",
        "c = tf.sqrt(a)\n",
        "d = b + c\n",
        "e = tf.matmul(a, b)\n",
        "e *= d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CPQYLICzI57P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePtKIPKHHyon"
      },
      "source": [
        "#### A second look at the GradientTape API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5CtV4l-Hyon"
      },
      "source": [
        "**Using the `GradientTape`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_O9b0RKNHyon"
      },
      "outputs": [],
      "source": [
        "input_var = tf.Variable(initial_value=5.)\n",
        "with tf.GradientTape() as tape:\n",
        "   result = tf.square(input_var)\n",
        "gradient = tape.gradient(result, input_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGjN9Cv4Hyoo"
      },
      "source": [
        "**Using `GradientTape` with constant tensor inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvCsU8XbHyoo"
      },
      "outputs": [],
      "source": [
        "input_const = tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "   tape.watch(input_const)\n",
        "   result = tf.square(input_const)\n",
        "gradient = tape.gradient(result, input_const)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPq7mC3yHyoo"
      },
      "source": [
        "**Using nested gradient tapes to compute second-order gradients**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KLqQOcObHyoo"
      },
      "outputs": [],
      "source": [
        "time = tf.Variable(10.)\n",
        "with tf.GradientTape() as outer_tape:\n",
        "    with tf.GradientTape() as inner_tape:\n",
        "        position =  4.9 * time ** 2\n",
        "    speed = inner_tape.gradient(position, time)\n",
        "acceleration = outer_tape.gradient(speed, time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik0yxaAvHyoo"
      },
      "source": [
        "#### An end-to-end example: A linear classifier in pure TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-jVPG3uHyoo"
      },
      "source": [
        "**Generating two classes of random points in a 2D plane**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "CMa7tTizHyop"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "num_samples_per_class = 1000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHzRpN2ZHyop"
      },
      "source": [
        "**Stacking the two classes into an array with shape (2000, 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAmJi9QnHyop"
      },
      "outputs": [],
      "source": [
        "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCJTlANLHyop"
      },
      "source": [
        "**Generating the corresponding targets (0 and 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9rSvcNRHyoq"
      },
      "outputs": [],
      "source": [
        "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
        "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgyOUkb2Hyoq"
      },
      "source": [
        "**Plotting the two point classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-lrHxfQHyoq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClaC2vy8Hyoq"
      },
      "source": [
        "**Creating the linear classifier variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrpPpuSIHyor"
      },
      "outputs": [],
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFW8Qj_pHyor"
      },
      "source": [
        "**The forward pass function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGlyiZwoHyor"
      },
      "outputs": [],
      "source": [
        "def model(inputs):\n",
        "    return tf.matmul(inputs, W) + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFpH--GHyor"
      },
      "source": [
        "**The mean squared error loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekJnEFXKHyor"
      },
      "outputs": [],
      "source": [
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions)\n",
        "    return tf.reduce_mean(per_sample_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo9cUcBfHyor"
      },
      "source": [
        "**The training step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwBiI_t6Hyos"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs)\n",
        "        loss = square_loss(predictions, targets)\n",
        "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
        "    W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
        "    b.assign_sub(grad_loss_wrt_b * learning_rate)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjDfitriHyos"
      },
      "source": [
        "**The batch training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka1oEWs1Hyos"
      },
      "outputs": [],
      "source": [
        "for step in range(40):\n",
        "    loss = training_step(inputs, targets)\n",
        "    print(f\"Loss at step {step}: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2--JOc-Hyos"
      },
      "outputs": [],
      "source": [
        "predictions = model(inputs)\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R781676MHyos"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 4, 100)\n",
        "y = - W[0] /  W[1] * x + (0.5 - b) / W[1]\n",
        "plt.plot(x, y, \"-r\")\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC-tNJ0wHyos"
      },
      "source": [
        "## Anatomy of a neural network: Understanding core Keras APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3JPYUHyot"
      },
      "source": [
        "### Layers: The building blocks of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etGdYM4PHyot"
      },
      "source": [
        "#### The base Layer class in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0JrM3-xHyot"
      },
      "source": [
        "**A `Dense` layer implemented as a `Layer` subclass**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-vyJbRqHyot"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class SimpleDense(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, activation=None):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "        self.W = self.add_weight(shape=(input_dim, self.units),\n",
        "                                 initializer=\"random_normal\")\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer=\"zeros\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = tf.matmul(inputs, self.W) + self.b\n",
        "        if self.activation is not None:\n",
        "            y = self.activation(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9QbH8gnHyot"
      },
      "outputs": [],
      "source": [
        "my_dense = SimpleDense(units=32, activation=tf.nn.relu)\n",
        "input_tensor = tf.ones(shape=(2, 784))\n",
        "output_tensor = my_dense(input_tensor)\n",
        "print(output_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsnZoIeUHyot"
      },
      "source": [
        "#### Automatic shape inference: Building layers on the fly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaPmt1PWHyot"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "layer = layers.Dense(32, activation=\"relu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0F1a-RNHyou"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "model = models.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(32)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7lAAJmaHyou"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    SimpleDense(32, activation=\"relu\"),\n",
        "    SimpleDense(64, activation=\"relu\"),\n",
        "    SimpleDense(32, activation=\"relu\"),\n",
        "    SimpleDense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXkaPlzqHyou"
      },
      "source": [
        "### From layers to models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4O_JCzhHyou"
      },
      "source": [
        "### The \"compile\" step: Configuring the learning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzbJr07vHyou"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1)])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"mean_squared_error\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QrzQ_iwHyou"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XFdJjEHHyou"
      },
      "source": [
        "### Picking a loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL99RfCBHyov"
      },
      "source": [
        "### Understanding the fit() method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGeHXNJ4Hyov"
      },
      "source": [
        "**Calling `fit()` with NumPy data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N3JyPA1Hyov"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    inputs,\n",
        "    targets,\n",
        "    epochs=5,\n",
        "    batch_size=128\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn-ne-VZHyov"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzYOEd28Hyov"
      },
      "source": [
        "### Monitoring loss and metrics on validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAAHqGsgHyov"
      },
      "source": [
        "**Using the `validation_data` argument**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azajvg37Hyow"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1)])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.1),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "indices_permutation = np.random.permutation(len(inputs))\n",
        "shuffled_inputs = inputs[indices_permutation]\n",
        "shuffled_targets = targets[indices_permutation]\n",
        "\n",
        "num_validation_samples = int(0.3 * len(inputs))\n",
        "val_inputs = shuffled_inputs[:num_validation_samples]\n",
        "val_targets = shuffled_targets[:num_validation_samples]\n",
        "training_inputs = shuffled_inputs[num_validation_samples:]\n",
        "training_targets = shuffled_targets[num_validation_samples:]\n",
        "model.fit(\n",
        "    training_inputs,\n",
        "    training_targets,\n",
        "    epochs=5,\n",
        "    batch_size=16,\n",
        "    validation_data=(val_inputs, val_targets)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY4nQy9_Hyow"
      },
      "source": [
        "### Inference: Using a model after training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbabh3VKHyow"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(val_inputs, batch_size=128)\n",
        "print(predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pExRxPW5Hyow"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "capitulo3",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}